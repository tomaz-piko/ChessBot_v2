{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:31:52.147748: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from model import load_as_trt_model\n",
    "from rchess import Board, Move\n",
    "from utils import FakeTRTFunc\n",
    "import numpy as np\n",
    "from configs import engineplayConfig, selfplayConfig\n",
    "from mcts import MCTS, debug_search, Node\n",
    "\n",
    "selfplayConfig[\"tablebase_search\"] = True\n",
    "mctsSearch = MCTS(selfplayConfig)\n",
    "use_fake = True\n",
    "if use_fake:\n",
    "    trt_func = FakeTRTFunc()\n",
    "else:\n",
    "    trt_func, _ = load_as_trt_model(\"latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import Board as PyBoard\n",
    "#board = Board(\"1r2k3/1P6/1K6/8/8/2R5/2p5/8 w - - 0 1\")\n",
    "#board = Board(\"6k1/8/8/3P4/8/8/8/K7 b - - 0 1\")\n",
    "board = Board(\"2k5/4p1n1/4Pp2/5P2/5K2/8/3R4/8 b - - 8 6\")\n",
    "pyBoard = PyBoard(board.fen())\n",
    "#print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   | k |   |   |   |   |   | 8\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   | p |   | n |   | 7\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   | P | p |   |   | 6\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   | P |   |   | 5\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   | K |   |   | 4\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   |   |   |   | 3\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   | R |   |   | 2\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   |   |   |   | 1\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "    a   b   c   d   e   f   g   h\n",
      "\n",
      "Fen: 2k5/4p1n1/4Pp2/5P2/5K2/8/5R2/8 w - - 11 8\n",
      "Key: 10a95ef126cecbbb\n",
      "Elapsed time: 5.22s\n",
      "Total visits: 39936\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "PV:\n",
      "1. 0.491103 | f2e2 c8d8 e2g2 g7h5 f4f3 d8c8 g2e2 h5g7 f3f2 c8b7\n",
      "2. 0.483573 | f2h2 c8b8 h2b2 b8a8 b2b8 a8a7 b8g8 g7h5 f4e4 a7a6\n",
      "3. 0.473083 | f2b2 g7e8 f4e4 c8d8 e4d5 d8c8 d5c5 c8d8 c5b4\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Move             Visits     Policy         Avg. value       UCB              Q+U                Raw NN Value\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "f2e2  (844   )   N: 4792    (P:   7.23%)   (Q:  0.491103)   (U:  0.501941)   (Q+U:  0.993044)   (V:  0.035538)\n",
      "f2h2  (847   )   N: 4742    (P:  13.74%)   (Q:  0.483573)   (U:  0.501778)   (Q+U:  0.985351)   (V:  0.341767)\n",
      "f2b2  (841   )   N: 3903    (P:  15.72%)   (Q:  0.473083)   (U:  0.501616)   (Q+U:  0.974699)   (V:  0.116110)\n",
      "f2f1  (837   )   N: 3773    (P:   5.87%)   (Q:  0.490677)   (U:  0.501858)   (Q+U:  0.992535)   (V:  0.237344)\n",
      "f2f3  (853   )   N: 3738    (P:   7.31%)   (Q:  0.487921)   (U:  0.501670)   (Q+U:  0.989592)   (V:  0.189340)\n",
      "f2g2  (846   )   N: 3030    (P:   5.25%)   (Q:  0.489795)   (U:  0.501625)   (Q+U:  0.991420)   (V:  0.089469)\n",
      "f2a2  (840   )   N: 2953    (P:   5.13%)   (Q:  0.490465)   (U:  0.501826)   (Q+U:  0.992290)   (V:  0.076772)\n",
      "f4e4  (1884  )   N: 2943    (P:   3.77%)   (Q:  0.492564)   (U:  0.501777)   (Q+U:  0.994341)   (V:  0.271738)\n",
      "f4g4  (1886  )   N: 2552    (P:   5.76%)   (Q:  0.486456)   (U:  0.501468)   (Q+U:  0.987925)   (V:  0.135132)\n",
      "f4g3  (1878  )   N: 2373    (P:   7.28%)   (Q:  0.479856)   (U:  0.501914)   (Q+U:  0.981770)   (V:  0.440728)\n",
      "f4f3  (1877  )   N: 1570    (P:   9.08%)   (Q:  0.460384)   (U:  0.501928)   (Q+U:  0.962313)   (V:  0.368368)\n",
      "f4e3  (1876  )   N: 1486    (P:   5.33%)   (Q:  0.476029)   (U:  0.501804)   (Q+U:  0.977833)   (V:  0.211495)\n",
      "f2c2  (842   )   N: 1132    (P:   4.26%)   (Q:  0.474899)   (U:  0.501909)   (Q+U:  0.976808)   (V:  0.377475)\n",
      "f2d2  (843   )   N: 948     (P:   4.27%)   (Q:  0.469522)   (U:  0.501892)   (Q+U:  0.971414)   (V:  0.030027)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Move.from_uci('f2e2')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move, root, child_visits = mctsSearch.find_best_move(board, None, trt_func, 0, 5.0, True)\n",
    "debug_search(board, root, 3, 10)\n",
    "board.push_num(move)\n",
    "move_uci = Move(move).uci()\n",
    "pyBoard.push_uci(move_uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . k . . . . .\n",
       ". . . . p . n .\n",
       ". . . . P p . .\n",
       ". . . . . P . .\n",
       ". . . . . K . .\n",
       ". . . . . . . .\n",
       ". . . . R . . .\n",
       ". . . . . . . .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light lastmove e2\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark lastmove f2\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(195, 285)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(240, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 150)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 60)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(105, 15)\" /></svg>"
      ],
      "text/plain": [
       "Board('2k5/4p1n1/4Pp2/5P2/5K2/8/4R3/8 b - - 12 8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: [[0.00239372]]\n",
      "Policies: [[ 0.73828125  0.9121094   0.81933594 ... -0.3786621   0.89160156\n",
      "   1.0566406 ]]\n",
      "Max policy: 1.5595703\n",
      "Min policy: -0.8125\n",
      "Mean policy: 0.0023056436\n"
     ]
    }
   ],
   "source": [
    "from model import predict_fn\n",
    "board = Board(\"5k1r/1b2rp2/pR4pp/1p3n2/2p5/2N5/PP3PPP/3Q2K1 w - -\")\n",
    "image, hash = board.history(engineplayConfig[\"history_perspective_flip\"])\n",
    "value, policies = predict_fn(trt_func, np.array([image]))\n",
    "print(\"Value:\", value.numpy())\n",
    "print(\"Policies:\", policies.numpy())\n",
    "# Max of policies and min of policies\n",
    "policies = policies.numpy()[0]\n",
    "print(\"Max policy:\", np.max(policies))\n",
    "print(\"Min policy:\", np.min(policies))\n",
    "print(\"Mean policy:\", np.mean(policies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 122880 samples, taking 73728 samples\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from configs import trainingConfig as tcfg\n",
    "from functools import partial\n",
    "\n",
    "def count_available_samples(config):\n",
    "    \"\"\" Count the number of available samples for training.\n",
    "\n",
    "    Args:\n",
    "        config (dict): A dictionary containing the configuration for the project.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of available samples for training.\n",
    "        int: The number of samples to use after sampling.\n",
    "    \"\"\"\n",
    "    sample_dir = os.path.join(config['project_dir'], 'data', 'selfplay_data')\n",
    "    total_samples = 0\n",
    "    sampling_ratio = config['sampling_ratio']\n",
    "\n",
    "    for filename in os.listdir(sample_dir):\n",
    "        if filename.endswith('.npz'):\n",
    "            num_positions = int(filename.split('_')[0])\n",
    "            total_samples += num_positions\n",
    "\n",
    "    return total_samples, int(total_samples * sampling_ratio)\n",
    "\n",
    "def load_samples(config, load: int, take: int):\n",
    "    print(f\"Loading {load} samples, taking {take} samples\")\n",
    "    sample_dir = os.path.join(config['project_dir'], 'data', 'selfplay_data')\n",
    "    samples = []\n",
    "\n",
    "    loaded_samples = 0\n",
    "\n",
    "    # Get list of files and sort them by the number of samples (least samples first)\n",
    "    files = [f for f in os.listdir(sample_dir) if f.endswith('.npz')]\n",
    "    files.sort(key=lambda f: int(f.split('_')[0]))\n",
    "\n",
    "    for filename in files:\n",
    "        if filename.endswith('.npz'):\n",
    "            file_path = os.path.join(sample_dir, filename)\n",
    "            data = np.load(file_path)\n",
    "            images = data['images']\n",
    "            search_stats = data['search_stats']\n",
    "            terminal_values = data['terminal_values']\n",
    "            num_file_samples = len(images)\n",
    "\n",
    "            if loaded_samples + num_file_samples <= load:\n",
    "                samples.extend((images[i], (search_stats[i], terminal_values[i])) for i in range(num_file_samples))\n",
    "                loaded_samples += num_file_samples\n",
    "            else:\n",
    "                remaining_samples = load - loaded_samples\n",
    "                samples.extend((images[i], (search_stats[i], terminal_values[i])) for i in range(remaining_samples))\n",
    "                loaded_samples += remaining_samples\n",
    "\n",
    "                # Save the remaining data back to a new file with a new name, {remaining_samples}_{timestamp}\n",
    "                timestamp = datetime.now().strftime('%F_%T.%f')[:-3]\n",
    "                new_filename = f\"{remaining_samples}_{timestamp}.npz\"\n",
    "                np.savez(os.path.join(sample_dir, new_filename), \n",
    "                         images=images[remaining_samples:].astype(np.int64), \n",
    "                         search_stats=search_stats[remaining_samples:],\n",
    "                         terminal_values=terminal_values[remaining_samples:].astype(np.int64))\n",
    "                \n",
    "                break\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    # Randomly select num_selected_samples from samples, each sample can be selected only once\n",
    "    indices = rng.choice(len(samples), size=take, replace=False)\n",
    "    selected_samples = [samples[i] for i in indices]\n",
    "    return selected_samples\n",
    "\n",
    "def create_tf_record(config, samples):\n",
    "    timestamp = datetime.now().strftime('%F_%T.%f')[:-3]\n",
    "    save_path = os.path.join(config['project_dir'], 'data', 'train_data', f\"{timestamp}.tfrecords\")\n",
    "    with tf.io.TFRecordWriter(save_path) as writer:\n",
    "        for sample in samples:\n",
    "            image, (search_stats, terminal_value) = sample\n",
    "            \n",
    "            image_features = tf.train.Feature(int64_list=tf.train.Int64List(value=image))\n",
    "            search_stats_features = tf.train.Feature(float_list=tf.train.FloatList(value=search_stats))\n",
    "            terminal_value_features = tf.train.Feature(float_list=tf.train.FloatList(value=[terminal_value]))\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"image\": image_features,\n",
    "                \"value_head\": terminal_value_features,\n",
    "                \"policy_head\": search_stats_features\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())\n",
    "    return save_path\n",
    "\n",
    "def read_tfrecord(example_proto):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([109], tf.int64),\n",
    "        \"value_head\": tf.io.FixedLenFeature([1], tf.float32),\n",
    "        \"policy_head\": tf.io.FixedLenFeature([1858], tf.float32),\n",
    "    }\n",
    "    example_proto = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return example_proto[\"image\"], {\"value_head\": example_proto[\"value_head\"], \"policy_head\": example_proto[\"policy_head\"]}\n",
    "\n",
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_dataset(filenames, batch_size, buffer_size=4096):\n",
    "    dataset = load_dataset(filenames)\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "batch_size = 4096\n",
    "total_samples, sampled_samples = count_available_samples(tcfg)\n",
    "epochs = sampled_samples // batch_size\n",
    "\n",
    "num_samples = batch_size * epochs\n",
    "\n",
    "samples = load_samples(tcfg, round(num_samples / tcfg['sampling_ratio']), num_samples)\n",
    "tf_record = create_tf_record(tcfg, samples)\n",
    "data_set = get_dataset(tf_record, 4096, buffer_size=40960*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"value_head\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"policy_head\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0450563207\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0475594476\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0538172722\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0450563207\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0337922387\n",
      "        value: 0\n",
      "        value: 0.0550688356\n",
      "        value: 0\n",
      "        value: 0.0463078842\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0125156445\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0150187733\n",
      "        value: 0.0400500633\n",
      "        value: 0.0337922387\n",
      "        value: 0.0287859831\n",
      "        value: 0.0463078842\n",
      "        value: 0\n",
      "        value: 0.0287859831\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0250312891\n",
      "        value: 0.0200250316\n",
      "        value: 0.0137672089\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0438047573\n",
      "        value: 0.0137672089\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0387985\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0438047573\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0262828544\n",
      "        value: 0.0212765951\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0300375465\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0500625782\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0438047573\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0175219029\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0287859831\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0.0513141416\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 36420266376560640\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 2251799813685248\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 262144\n",
      "        value: 512\n",
      "        value: 1073741824\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 36420266376560640\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 2251799813685248\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 262144\n",
      "        value: 512\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 40888681631842304\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 2251799813685248\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 35184372350976\n",
      "        value: 512\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 40888681631842304\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 2251799813685248\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 35184372088834\n",
      "        value: 512\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 40890872065163264\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 2251799813685248\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 35184372088834\n",
      "        value: 512\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 40890872065163264\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 2251799813685248\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 1073741826\n",
      "        value: 512\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 40890872065163264\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 1152921504606846976\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 1073741826\n",
      "        value: 512\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 40890872065163264\n",
      "        value: 144115188075855872\n",
      "        value: 1\n",
      "        value: -9151314442816847872\n",
      "        value: 1152921504606846976\n",
      "        value: 288230376151711744\n",
      "        value: 274919926784\n",
      "        value: 1073741826\n",
      "        value: 4\n",
      "        value: 16384\n",
      "        value: 8\n",
      "        value: 16\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "sample = samples[2]\n",
    "\n",
    "image, (search_stats, terminal_value) = sample\n",
    "            \n",
    "image_features = tf.train.Feature(int64_list=tf.train.Int64List(value=image))\n",
    "search_stats_features = tf.train.Feature(float_list=tf.train.FloatList(value=search_stats))\n",
    "terminal_value_features = tf.train.Feature(float_list=tf.train.FloatList(value=[terminal_value]))\n",
    "\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    \"image\": image_features,\n",
    "    \"value_head\": terminal_value_features,\n",
    "    \"policy_head\": search_stats_features\n",
    "}))\n",
    "\n",
    "for line in str(example).split('\\n'):\n",
    "  print(line)\n",
    "print('...')\n",
    "example_proto = example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal value: [0.]\n"
     ]
    }
   ],
   "source": [
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([109], tf.int64),\n",
    "    \"value_head\": tf.io.FixedLenFeature([1], tf.float32),\n",
    "    \"policy_head\": tf.io.FixedLenFeature([1858], tf.float32),\n",
    "}\n",
    "parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "image = parsed_example['image']\n",
    "terminal_value = parsed_example['value_head']\n",
    "search_stats = parsed_example['policy_head']\n",
    "print(\"Terminal value:\", terminal_value.numpy())\n",
    "\n",
    "#value_head = example_proto[\"value_head\"]\n",
    "#policy_head = example_proto[\"policy_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import generate_model\n",
    "model = generate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n",
      "Value: 0.4847373\n",
      "Policies: [-0.2803736   0.25383404 -0.07286161 ... -0.1049448   0.15348823\n",
      " -0.45927405]\n"
     ]
    }
   ],
   "source": [
    "value, policies = model.predict(np.expand_dims(image, axis=0))\n",
    "print(\"Value:\", value[0][0])\n",
    "print(\"Policies:\", policies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples loaded: 73728\n",
      "Sampling ratio: 0.6\n",
      "Count of terminal values in samples: {1.0: 17117, 0.0: 39264, -1.0: 17347}\n",
      "Sum of terminal values in samples: 73728\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples loaded:\", len(samples))\n",
    "print(\"Sampling ratio:\", tcfg['sampling_ratio'])\n",
    "# Count how many times in terminal_values in samples the value is -1.0, 0.0 and 1.0\n",
    "count = {1.0: 0, 0.0: 0, -1.0: 0}\n",
    "for sample in samples:\n",
    "    _, (_, terminal_value) = sample\n",
    "    count[terminal_value] += 1\n",
    "print(\"Count of terminal values in samples:\", count)\n",
    "# Sum the counted values\n",
    "sum = 0\n",
    "for k, v in count.items():\n",
    "    sum += v\n",
    "print(\"Sum of terminal values in samples:\", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: ['10000_2025-03-22_15:05:23.931.npz', '10000_2025-03-23_01:06:58.591.npz', '4454_2025-03-24_05:25:51.496.npz', '10000_2025-03-23_03:56:54.105.npz', '3815_2025-04-01_15:02:53.081.npz', '10000_2025-03-22_17:34:39.545.npz', '10000_2025-03-22_14:44:04.791.npz', '4611_2025-03-24_05:25:53.933.npz', '10000_2025-03-23_04:18:04.553.npz', '10000_2025-03-22_15:47:44.971.npz', '10000_2025-03-23_05:41:06.177.npz', '10000_2025-03-22_16:30:07.635.npz', '10000_2025-03-22_18:16:06.354.npz', '10000_2025-03-22_15:26:49.662.npz', '10000_2025-03-23_00:03:22.926.npz']\n",
      "Shuffled files: ['10000_2025-03-22_15:05:23.931.npz', '10000_2025-03-23_01:06:58.591.npz', '4611_2025-03-24_05:25:53.933.npz', '10000_2025-03-22_15:47:44.971.npz', '10000_2025-03-22_18:16:06.354.npz', '10000_2025-03-22_16:30:07.635.npz', '10000_2025-03-23_00:03:22.926.npz', '10000_2025-03-23_05:41:06.177.npz', '10000_2025-03-22_14:44:04.791.npz', '10000_2025-03-22_17:34:39.545.npz', '10000_2025-03-23_03:56:54.105.npz', '10000_2025-03-23_04:18:04.553.npz', '4454_2025-03-24_05:25:51.496.npz', '10000_2025-03-22_15:26:49.662.npz', '3815_2025-04-01_15:02:53.081.npz']\n"
     ]
    }
   ],
   "source": [
    "from configs import trainingConfig as config\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sample_dir = os.path.join(config['project_dir'], 'data', 'selfplay_data')\n",
    "restore_dir = os.path.join(config['restore_dir'])\n",
    "samples = []\n",
    "\n",
    "loaded_samples = 0\n",
    "\n",
    "# Get list of files and sort them by the number of samples (least samples first)\n",
    "files = [f for f in os.listdir(sample_dir) if f.endswith('.npz')]\n",
    "print(\"Files:\", files)\n",
    "\n",
    "np.random.shuffle(files)\n",
    "print(\"Shuffled files:\", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "from configs import selfplayConfig\n",
    "import os\n",
    "import re\n",
    "from math import ceil\n",
    "\n",
    "def _load_mosca_sts() -> list:\n",
    "    \"\"\"Parses the STS test suite file and returns a list of tests\n",
    "\n",
    "    Returns:\n",
    "        list: List of tests. Each test is a dictionary with the following:\n",
    "            - fen: FEN string of the position\n",
    "            - group: Group name (15 motifs in total)\n",
    "            - results: Dictionary with UCI move as key and score as value (multiple winning moves but one is still best)\n",
    "    \"\"\"\n",
    "\n",
    "    fileR = open(os.path.join(selfplayConfig['project_dir'], 'test_suites', 'STS1-STS15_LAN_v3.epd'), \"r\")\n",
    "    lines = fileR.readlines()\n",
    "    fileR.close()\n",
    "\n",
    "    tests = []\n",
    "    for line in lines:\n",
    "        line_info = line.split('; ')\n",
    "        fen = line_info[0].split(' bm ')[0]\n",
    "        for info in line_info:\n",
    "            if 'id' in info:\n",
    "                id = re.findall(r'\"([^\"]*)\"', info)[0]\n",
    "        group = id[:-4]\n",
    "        uci_moves = re.findall(r'\"([^\"]*)\"', line_info[-1])[0].split(' ')\n",
    "        moves_points = [int(points) for points in re.findall(r'\"([^\"]*)\"', line_info[-2])[0].split(' ')]\n",
    "        results = {uci_moves[i]: moves_points[i] for i in range(len(uci_moves))}\n",
    "        test = {\"fen\": fen, \"group\": group, \"results\": results}\n",
    "        tests.append(test)\n",
    "    return tests\n",
    "\n",
    "def _chunk_into_n(lst: list, n: int) -> list:\n",
    "    \"\"\"Splits an array into n chunks\n",
    "\n",
    "    Args:\n",
    "        lst (list): List to be splitted\n",
    "        n (int): Number of chunks\n",
    "\n",
    "    Returns:\n",
    "        list: List of n chunks (last chunk may be smaller than the rest)\n",
    "    \"\"\"\n",
    "    size = ceil(len(lst) / n)\n",
    "    return list(\n",
    "        map(lambda x: lst[x * size:x * size + size],\n",
    "        list(range(n)))\n",
    "    )\n",
    "\n",
    "num_actors = 1\n",
    "tests = _load_mosca_sts()\n",
    "test_chunks = _chunk_into_n(tests, num_actors)\n",
    "print(len(test_chunks))\n",
    "print(len(test_chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 15:03:27.456823: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:87] DefaultLogger 3: [runtime.cpp::~Runtime::346] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::346, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import load_as_trt_model\n",
    "from rchess import Board, Move\n",
    "import numpy as np\n",
    "from configs import selfplayConfig\n",
    "from mcts import MCTS, debug_search, Node\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "mctsSearch = MCTS(selfplayConfig)\n",
    "trt_func, _ = load_as_trt_model(model_version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | r |   | b | q |   | b |   | r | 8\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | p | p | p | p | k | p | p | p | 7\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   | n |   |   | n |   |   | 6\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   | p |   |   |   | 5\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   | B |   | P |   |   |   | 4\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   | Q |   |   | 3\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | P | P | P | P |   | P | P | P | 2\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | R | N | B |   | K |   | N | R | 1\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "    a   b   c   d   e   f   g   h\n",
      "\n",
      "Fen: r1bq1b1r/ppppkppp/2n2n2/4p3/2B1P3/5Q2/PPPP1PPP/RNB1K1NR w KQ - 6 5\n",
      "Key: 2dfcf5db51071a30\n"
     ]
    }
   ],
   "source": [
    "from rchess import Board, Move\n",
    "from configs import selfplayConfig\n",
    "\n",
    "def terminal_value(on_turn, winner):\n",
    "    if winner == on_turn:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "# Scholars mate\n",
    "images = []\n",
    "\n",
    "moves = [\"e2e4\", \"e7e5\", \"f1c4\", \"b8c6\", \"d1h5\", \"g8f6\", \"h5f3\", \"e8e7\"]\n",
    "moves_played = 0\n",
    "\n",
    "board = Board()\n",
    "while 1:\n",
    "    terminal, winner = board.terminal()\n",
    "    if terminal:\n",
    "        break\n",
    "\n",
    "    # MCTS SEARCH\n",
    "\n",
    "    if moves_played >= len(moves):\n",
    "        break\n",
    "    move = moves[moves_played]\n",
    "\n",
    "    history, _  = board.history(False)\n",
    "    images.append(history)\n",
    "\n",
    "    board.push_uci(move)\n",
    "    moves_played += 1\n",
    "\n",
    "terminal_values = [0.0] * moves_played\n",
    "if winner is not None:\n",
    "    for i in range(moves_played):\n",
    "        terminal_values[i] = terminal_value(True if i % 2 == 0 else False, winner)\n",
    "\n",
    "print(\"Terminal values:\", terminal_values)\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import convert_u64_to_np\n",
    "\n",
    "def visualize_image(image, ts):\n",
    "    \n",
    "    p1_img = np.zeros((8, 8), dtype=np.int8)\n",
    "    p2_img = np.zeros((8, 8), dtype=np.int8)\n",
    "    curr_ts_p1 = image[(ts*13):(ts*13)+6]\n",
    "    curr_ts_p2 = image[(ts*13)+6:(ts*13)+12]\n",
    "\n",
    "\n",
    "    for piece in range(6):\n",
    "        p1_pieces = curr_ts_p1[piece]\n",
    "        p2_pieces = curr_ts_p2[piece]\n",
    "        piece_value = piece + 1\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if p1_pieces[i,j] != 0:\n",
    "                    p1_img[i,j] = piece_value\n",
    "                if p2_pieces[i,j] != 0:\n",
    "                    p2_img[i,j] = piece_value\n",
    "    \n",
    "\n",
    "    return p1_img, p2_img\n",
    "\n",
    "images_np = convert_u64_to_np(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS:  0\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 2 0 0 2 0 0]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [4 0 3 5 6 3 0 4]]\n",
      "---------------------------\n",
      "[[4 2 3 0 6 0 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 5 0 0]\n",
      " [0 0 3 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  1\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 2 0 0 2 0 0]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [4 0 3 5 6 3 0 4]]\n",
      "---------------------------\n",
      "[[4 2 3 0 6 0 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 5]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  2\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 2 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [4 0 3 5 6 3 2 4]]\n",
      "---------------------------\n",
      "[[4 2 3 0 6 0 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 5]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  3\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 2 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [4 0 3 5 6 3 2 4]]\n",
      "---------------------------\n",
      "[[4 2 3 5 6 0 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  4\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [4 2 3 5 6 3 2 4]]\n",
      "---------------------------\n",
      "[[4 2 3 5 6 0 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  5\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [4 2 3 5 6 3 2 4]]\n",
      "---------------------------\n",
      "[[4 2 3 5 6 3 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  6\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [4 2 3 5 6 3 2 4]]\n",
      "---------------------------\n",
      "[[4 2 3 5 6 3 2 4]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n",
      "TS:  7\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [4 2 3 5 6 3 2 4]]\n",
      "---------------------------\n",
      "[[4 2 3 5 6 3 2 4]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = images_np[-1]\n",
    "for i in range(8):\n",
    "    p1, p2 = visualize_image(image, i)\n",
    "\n",
    "    print(\"TS: \", i)\n",
    "    print(p1)\n",
    "    print(\"---------------------------\")\n",
    "    print(p2)\n",
    "    print(\"   \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "def count_available_samples(config):\n",
    "    sample_dir = os.path.join(config['project_dir'], 'data', 'selfplay_data')\n",
    "    total_samples = 0\n",
    "    sampling_ratio = config['sampling_ratio']\n",
    "\n",
    "    for filename in os.listdir(sample_dir):\n",
    "        if filename.endswith('.npz'):\n",
    "            num_positions = int(filename.split('_')[0])\n",
    "            total_samples += num_positions\n",
    "\n",
    "    return total_samples, int(total_samples * sampling_ratio)\n",
    "\n",
    "def load_samples(config, load: int, take: int):\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    sample_dir = os.path.join(config['project_dir'], 'data', 'selfplay_data')\n",
    "    restore_dir = os.path.join(config['restore_dir'])\n",
    "    samples = []\n",
    "\n",
    "    # Get list of files and sort them by the number of samples (least samples first)\n",
    "    files = [f for f in os.listdir(sample_dir) if f.endswith('.npz')]\n",
    "    rng.shuffle(files)\n",
    "\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(sample_dir, filename)\n",
    "        data = np.load(file_path)\n",
    "        images = data['images']\n",
    "        search_stats = data['search_stats']\n",
    "        terminal_values = data['terminal_values']\n",
    "        num_file_samples = len(images)\n",
    "\n",
    "        if len(samples) + num_file_samples <= load:\n",
    "            for image, search_stat, terminal_value in zip(images, search_stats, terminal_values):\n",
    "                samples.append(\n",
    "                    {\n",
    "                        \"image\": image,\n",
    "                        \"value_head\": terminal_value,\n",
    "                        \"policy_head\": search_stat\n",
    "                    }\n",
    "                )\n",
    "        else:\n",
    "            remaining_samples = load - len(samples)\n",
    "            for image, search_stat, terminal_value in zip(images[:remaining_samples], search_stats[:remaining_samples], terminal_values[:remaining_samples]):\n",
    "                samples.append(\n",
    "                    {\n",
    "                        \"image\": image,\n",
    "                        \"value_head\": terminal_value,\n",
    "                        \"policy_head\": search_stat\n",
    "                    }\n",
    "                )\n",
    "             \n",
    "        if len(samples) >= load:\n",
    "                break\n",
    "    \n",
    "    # Randomly select num_selected_samples from samples, each sample can be selected only once\n",
    "    indices = rng.choice(len(samples), size=take, replace=False)\n",
    "    selected_samples = [samples[i] for i in indices]\n",
    "    rng.shuffle(selected_samples)\n",
    "    return selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  132880\n",
      "Epochs possible:  19\n",
      "Samples loaded:  77824\n"
     ]
    }
   ],
   "source": [
    "from configs import trainingConfig as config\n",
    "batch_size = 4096\n",
    "sampling_ratio = 0.6\n",
    "\n",
    "config[\"batch_size\"] = batch_size\n",
    "config[\"sampling_ratio\"] = sampling_ratio\n",
    "\n",
    "total_samples, sampled_samples = count_available_samples(config)\n",
    "epochs = sampled_samples // batch_size\n",
    "print(\"Total samples: \", total_samples)\n",
    "print(\"Epochs possible: \", epochs)\n",
    "num_samples = batch_size * epochs\n",
    "samples = load_samples(config, round(num_samples / config['sampling_ratio']), num_samples)\n",
    "print(\"Samples loaded: \", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (77824, 109)\n",
      "Search stats shape: (77824, 1858)\n",
      "Terminal values shape: (77824,)\n",
      "Terminal values: [ 0. -1.  0. ...  0.  1.  1.]\n",
      "{1.0: 18594, 0.0: 40941, -1.0: 18289}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "images = np.array([sample[\"image\"] for sample in samples])\n",
    "search_stats =  np.array([sample[\"policy_head\"] for sample in samples])\n",
    "terminal_values =  np.array([sample[\"value_head\"] for sample in samples], dtype=np.float32)\n",
    "\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Search stats shape:\", search_stats.shape)\n",
    "print(\"Terminal values shape:\", terminal_values.shape)\n",
    "print(\"Terminal values:\", terminal_values)\n",
    "\n",
    "count = {1.0: 0, 0.0: 0, -1.0: 0}\n",
    "for terminal_value in terminal_values:\n",
    "    count[terminal_value] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 15:08:07.928620: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-01 15:08:09.314459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from model import generate_model\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "Values: [[ 0.03153405]\n",
      " [ 0.20435306]\n",
      " [-0.05304952]\n",
      " [-0.00075198]\n",
      " [-0.00179523]\n",
      " [ 0.00356553]\n",
      " [ 0.00165041]\n",
      " [ 0.01062426]\n",
      " [-0.0616665 ]\n",
      " [ 0.03843891]\n",
      " [ 0.07385221]\n",
      " [ 0.27732942]\n",
      " [-0.01167445]\n",
      " [-0.0376427 ]\n",
      " [ 0.00209222]]\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.choice(len(images), size=15, replace=False)\n",
    "values, policies = model.predict(images[indices])\n",
    "print(\"Values:\", values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 15:08:15.572529: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 578387968 exceeds 10% of free system memory.\n",
      "2025-04-01 15:08:15.992517: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 578387968 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.8143 - value_head_loss: 0.6572 - policy_head_loss: 7.8345 - lr: 0.0200\n",
      "Epoch 2/19\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.7287 - value_head_loss: 0.6285 - policy_head_loss: 7.7776 - lr: 0.0200\n",
      "Epoch 3/19\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5962 - value_head_loss: 0.5926 - policy_head_loss: 7.6810 - lr: 0.0200\n",
      "Epoch 4/19\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.4612 - value_head_loss: 0.6242 - policy_head_loss: 7.5144 - lr: 0.0200\n",
      "Epoch 5/19\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.2971 - value_head_loss: 0.5857 - policy_head_loss: 7.3889 - lr: 0.0200\n",
      "Epoch 6/19\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0462 - value_head_loss: 0.5465 - policy_head_loss: 7.1772 - lr: 0.0200\n",
      "Epoch 7/19\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.9953 - value_head_loss: 0.5770 - policy_head_loss: 7.0958 - lr: 0.0200\n",
      "Epoch 8/19\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.8275 - value_head_loss: 0.5073 - policy_head_loss: 6.9977 - lr: 0.0200\n",
      "Epoch 9/19\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.9046 - value_head_loss: 0.5695 - policy_head_loss: 7.0127 - lr: 0.0200\n",
      "Epoch 10/19\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.8016 - value_head_loss: 0.5639 - policy_head_loss: 6.9153 - lr: 0.0200\n",
      "Epoch 11/19\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.7567 - value_head_loss: 0.5349 - policy_head_loss: 6.8993 - lr: 0.0200\n",
      "Epoch 12/19\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.6262 - value_head_loss: 0.5003 - policy_head_loss: 6.8034 - lr: 0.0200\n",
      "Epoch 13/19\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.6068 - value_head_loss: 0.4877 - policy_head_loss: 6.7967 - lr: 0.0200\n",
      "Epoch 14/19\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.6507 - value_head_loss: 0.5257 - policy_head_loss: 6.8026 - lr: 0.0200\n",
      "Epoch 15/19\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5536 - value_head_loss: 0.4702 - policy_head_loss: 6.7609 - lr: 0.0200\n",
      "Epoch 16/19\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.5066 - value_head_loss: 0.4675 - policy_head_loss: 6.7166 - lr: 0.0200\n",
      "Epoch 17/19\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.4849 - value_head_loss: 0.4825 - policy_head_loss: 6.6800 - lr: 0.0200\n",
      "Epoch 18/19\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.4331 - value_head_loss: 0.4688 - policy_head_loss: 6.6419 - lr: 0.0200\n",
      "Epoch 19/19\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3932 - value_head_loss: 0.4446 - policy_head_loss: 6.6261 - lr: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79655c2f5f30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "        lambda _: config['learning_rate'],\n",
    ")\n",
    "callbacks = [lr_callback]\n",
    "\n",
    "learning_rate = 0.02\n",
    "config[\"learning_rate\"] = learning_rate\n",
    "\n",
    "model.fit(images, \n",
    "        (terminal_values, search_stats),\n",
    "        batch_size=1024, \n",
    "        initial_epoch=0, \n",
    "        epochs=epochs, \n",
    "        steps_per_epoch=1,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 15:03:38.748746: I tensorflow/compiler/tf2tensorrt/common/utils.cc:104] Linked TensorRT version: 8.4.3\n",
      "2025-04-01 15:03:38.748792: I tensorflow/compiler/tf2tensorrt/common/utils.cc:106] Loaded TensorRT version: 8.6.1\n",
      "2025-04-01 15:03:43.993883: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1330] [TF-TRT] Sparse compute capability: enabled.\n"
     ]
    }
   ],
   "source": [
    "#values, policies = predict_fn(trt_func, images[indices])\n",
    "#print(\"Values:\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/tomaz/ChessBot_v2/data/models/tmp/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/tomaz/ChessBot_v2/data/models/tmp/saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (8, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (8, 4, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded TensorRT version: (8, 6, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded TensorRT version: (8, 6, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded TensorRT 8.6.1 and linked TensorFlow against TensorRT 8.4.3. This is supported because TensorRT minor/patch upgrades are backward compatible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loaded TensorRT 8.6.1 and linked TensorFlow against TensorRT 8.4.3. This is supported because TensorRT minor/patch upgrades are backward compatible.\n",
      "2025-04-01 13:30:33.026521: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-04-01 13:30:33.026616: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2025-04-01 13:30:33.027784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6087 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing prior device assignments in loaded saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing prior device assignments in loaded saved model\n",
      "2025-04-01 13:30:33.990139: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-04-01 13:30:33.990233: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2025-04-01 13:30:33.991451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6087 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5\n",
      "2025-04-01 13:30:34.606699: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:186] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2025-04-01 13:30:34.781643: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:962] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- Cast -> 3x\n",
      "\t- StridedSlice -> 3x\n",
      "\t- Identity -> 2x\n",
      "\t- NoOp -> 2x\n",
      "\t- BitwiseAnd -> 1x\n",
      "\t- Const -> 1x\n",
      "\t- ExpandDims -> 1x\n",
      "\t- Placeholder -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 14\n",
      "\t- Total nonconverted OP Types: 8\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2025-04-01 13:30:34.782726: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1290] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 1 TRT Engines with  at least minimum_segment_size=3 nodes.\n",
      "2025-04-01 13:30:34.783079: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:799] Number of TensorRT candidate segments: 1\n",
      "2025-04-01 13:30:34.857920: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:913] Replaced segment 0 consisting of 120 nodes by TRTEngineOp_000_000.\n",
      "2025-04-01 13:30:37.786730: I tensorflow/compiler/tf2tensorrt/common/utils.cc:104] Linked TensorRT version: 8.4.3\n",
      "2025-04-01 13:30:37.786967: I tensorflow/compiler/tf2tensorrt/common/utils.cc:106] Loaded TensorRT version: 8.6.1\n",
      "2025-04-01 13:30:43.263960: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1330] [TF-TRT] Sparse compute capability: enabled.\n",
      "2025-04-01 13:31:06.018824: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:83] TF-TRT Warning: DefaultLogger TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "2025-04-01 13:31:06.018853: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:83] TF-TRT Warning: DefaultLogger Check verbose logs for the list of affected weights.\n",
      "2025-04-01 13:31:06.018863: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:83] TF-TRT Warning: DefaultLogger - 15 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "2025-04-01 13:31:06.018889: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:83] TF-TRT Warning: DefaultLogger - 1 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/tomaz/ChessBot_v2/data/models/tmp/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/tomaz/ChessBot_v2/data/models/tmp/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from model import predict_fn\n",
    "\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from configs import selfplayConfig as config\n",
    "import os\n",
    "precision_mode = \"FP16\"\n",
    "build_model = True\n",
    "\n",
    "def input_fn():\n",
    "    np_data = np.load(os.path.join(config['project_dir'], 'data', 'conversion_data', 'histories.npz'))\n",
    "    histories = np_data[\"histories\"]\n",
    "    # Yield the histories in batches of size defaultConfig[\"batch_size\"]\n",
    "    for i in range(0, len(histories), config[\"num_vl_searches\"]):\n",
    "        yield (histories[i:i + config[\"num_vl_searches\"]],)\n",
    "\n",
    "model_save_path = os.path.join(config['project_dir'], 'data', 'models', \"testing\", 'saved_model')\n",
    "\n",
    "tf_model = model\n",
    "tf_model.save(model_save_path)\n",
    "\n",
    "conversion_params = trt.TrtConversionParams(\n",
    "    precision_mode=precision_mode,\n",
    "    use_calibration=True,\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=model_save_path,\n",
    "    conversion_params=conversion_params,\n",
    ")\n",
    "\n",
    "if precision_mode == \"INT8\":\n",
    "    converter.convert(calibration_input_fn=input_fn)\n",
    "else:\n",
    "    converter.convert()\n",
    "\n",
    "if precision_mode != \"INT8\" and build_model:\n",
    "    converter.build(input_fn=input_fn)\n",
    "\n",
    "converter.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 13:31:14.737201: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:87] DefaultLogger 3: [runtime.cpp::~Runtime::346] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::346, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(model_save_path)\n",
    "trt_func = loaded_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moves: ['e2e3', 'e7e5']\n"
     ]
    }
   ],
   "source": [
    "words = \"position startpos moves e2e3 e7e5\"\n",
    "words = words.strip().split()\n",
    "moves_index = words.index(\"startpos\") + 1\n",
    "if \"moves\" in words:\n",
    "    moves = words[moves_index + 1:]\n",
    "print(\"Moves:\", moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "neki = [1, 2, 3]\n",
    "neki2 = neki[-2:]\n",
    "print(neki2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | r | n | b | q | k | b | n | r | 8\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | p | p | p | p |   | p | p | p | 7\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   |   |   |   | 6\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   | p |   |   |   | 5\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  |   |   |   |   |   |   |   |   | 4\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | N |   |   |   | P |   |   |   | 3\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | P | P | P | P |   | P | P | P | 2\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "  | R |   | B | Q | K | B | N | R | 1\n",
      "  +---+---+---+---+---+---+---+---+\n",
      "    a   b   c   d   e   f   g   h\n",
      "\n",
      "Fen: rnbqkbnr/pppp1ppp/8/4p3/8/N3P3/PPPP1PPP/R1BQKBNR b KQkq - 0 2\n",
      "Key: 5376f0d24d31f542\n"
     ]
    }
   ],
   "source": [
    "from rchess import Board\n",
    "board = Board(\"rnbqkbnr/pppp1ppp/8/4p3/8/N3P3/PPPP1PPP/R1BQKBNR b KQkq - 0 2\")\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def eval_to_centipawn(Q):\n",
    "    cp = 111.714640912 * math.tan(1.5620688421 * (2*Q-1))\n",
    "    \n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 0.50, cp/100: 0.00\n",
      "Q: 0.55, cp/100: 0.18\n",
      "Q: 0.60, cp/100: 0.36\n",
      "Q: 0.65, cp/100: 0.57\n",
      "Q: 0.70, cp/100: 0.81\n",
      "Q: 0.75, cp/100: 1.11\n",
      "Q: 0.80, cp/100: 1.52\n",
      "Q: 0.85, cp/100: 2.16\n",
      "Q: 0.90, cp/100: 3.36\n",
      "Q: 0.95, cp/100: 6.71\n",
      "Q: 1.00, cp/100: 128.00\n"
     ]
    }
   ],
   "source": [
    "# Example values\n",
    "Q_values = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "is_white_turn = True\n",
    "\n",
    "# Print centipawn values\n",
    "for Q in Q_values:\n",
    "    cp = eval_to_centipawn(Q)\n",
    "    #print(cp)\n",
    "    print(f\"Q: {Q:.2f}, cp/100: {cp/100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
