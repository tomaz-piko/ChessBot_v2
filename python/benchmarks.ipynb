{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3518ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version of MCTS implementation for performance comparison\n",
    "from mcts import MCTS\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from actionspace import map_w, map_b\n",
    "from rchess import Move, Board\n",
    "from model import predict_fn, predict_model\n",
    "from chess import Board as TbBoard\n",
    "import chess.syzygy as syzygy\n",
    "import os\n",
    "from configs import engineplayConfig\n",
    "\n",
    "class NodePy:\n",
    "    def __init__(self, p):\n",
    "        self.P = p\n",
    "        self.W = 0.0\n",
    "        self.N = 0\n",
    "        self.vloss = 0\n",
    "        self.children = {}\n",
    "        self.to_play = False\n",
    "        self.debug_info = {}\n",
    "\n",
    "    def __getitem__(self, move):\n",
    "        return self.children[move]\n",
    "    \n",
    "    def __setitem__(self, move, node):\n",
    "        self.children[move] = node\n",
    "\n",
    "    def get_child(self, move):\n",
    "        return self.children[move]\n",
    "\n",
    "    def add_child(self, move, p):\n",
    "        self.children[move] = NodePy(p)\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return not self.children\n",
    "\n",
    "    def apply_vloss(self):\n",
    "        self.N += 1\n",
    "        self.W -= 1\n",
    "        self.vloss += 1\n",
    "\n",
    "    def remove_vloss(self):\n",
    "        self.N -= self.vloss\n",
    "        self.W += self.vloss\n",
    "        self.vloss = 0\n",
    "\n",
    "class MCTSPy:\n",
    "    def __init__(self, cfg):\n",
    "        self.history_flip = cfg['history_perspective_flip']\n",
    "        self.root_exploration_noise = cfg['root_exploration_noise']\n",
    "        self.root_dirichlet_alpha = cfg['root_dirichlet_alpha']\n",
    "        self.root_exploration_fraction = cfg['root_exploration_fraction']\n",
    "        self.fpu_root = cfg['fpu_root']\n",
    "        self.fpu_leaf = cfg['fpu_leaf']\n",
    "        self.pb_c_init = cfg['pb_c_init']\n",
    "        self.pb_c_factor = cfg['pb_c_factor']\n",
    "        self.pb_c_base = cfg['pb_c_base']\n",
    "        self.moves_softmax_temp = cfg['moves_softmax_temp']\n",
    "        self.num_vl_searches = cfg['num_vl_searches']\n",
    "        self.num_mcts_sampling_moves = cfg['num_mcts_sampling_moves']\n",
    "        self.resignation_threshold = cfg['resignation_threshold']\n",
    "        self.tablebase_search = cfg['tablebase_search']\n",
    "\n",
    "        self.num_planes = 109\n",
    "        self.rng = np.random.default_rng()\n",
    "        self.m_w = map_w\n",
    "        self.m_b = map_b\n",
    "\n",
    "        self.tablebase = syzygy.open_tablebase(os.path.join(cfg['project_dir'], 'syzygy/3-4-5'))\n",
    "\n",
    "    def get_history_flip(self):\n",
    "        return self.history_flip\n",
    "\n",
    "    def expand_root(self, board, root, trt_func, debug):\n",
    "        if root is None:\n",
    "            root = NodePy(0.0) \n",
    "        batch = np.zeros((self.num_vl_searches, self.num_planes), dtype=np.int64)\n",
    "\n",
    "        root.to_play = board.to_play()\n",
    "        history, _ = board.history(self.history_flip)\n",
    "\n",
    "        for idx in range(self.num_planes):\n",
    "            batch[0, idx] = history[idx]\n",
    "        _, policy_logits = make_predictions_py(\n",
    "                trt_func=trt_func,\n",
    "                batch=batch\n",
    "            )\n",
    "        self.expand_and_evaluate_node(root, policy_logits[0], board.legal_moves_tuple(), debug)\n",
    "        return root\n",
    "\n",
    "    def search(self, board, root, trt_func, debug):\n",
    "        nodes_to_eval = []\n",
    "        moves_to_nodes = []\n",
    "        eval_nodes_legal_moves = []\n",
    "        failsafe = 0\n",
    "        nodes_found = 0\n",
    "        nodes_to_find = self.num_vl_searches\n",
    "        batch = np.zeros((self.num_vl_searches, self.num_planes), dtype=np.int64)\n",
    "\n",
    "        while nodes_found < nodes_to_find and failsafe < 2:\n",
    "            depth_to_root = 0\n",
    "            node = root\n",
    "            tmp_board = board.clone()\n",
    "            while not node.is_leaf():\n",
    "                fpu = self.fpu_leaf if depth_to_root > 0 else self.fpu_root\n",
    "                move_num = select_child_py(node, pb_c_base=self.pb_c_base, pb_c_init=self.pb_c_init, pb_c_factor=self.pb_c_factor, fpu=fpu, debug=debug)\n",
    "                node = node[move_num]\n",
    "                tmp_board.push_num(move_num)\n",
    "                depth_to_root += 1\n",
    "            \n",
    "            terminal, is_drawn = tmp_board.mid_search_terminal(depth_to_root)\n",
    "            if terminal:\n",
    "                value = 0.5 if is_drawn else 0.0\n",
    "                update_py(root, tmp_board.moves_history(depth_to_root), value)\n",
    "                if debug:\n",
    "                    node.debug_info[\"init_value\"] = flip_value_py(value)\n",
    "                failsafe += 1\n",
    "                continue\n",
    "\n",
    "            moves_to_node = tmp_board.moves_history(depth_to_root)\n",
    "            add_vloss_py(root, moves_to_node)\n",
    "\n",
    "            node.to_play = tmp_board.to_play()\n",
    "\n",
    "            nodes_to_eval.append(node)\n",
    "            moves_to_nodes.append(moves_to_node)\n",
    "            eval_nodes_legal_moves.append(tmp_board.legal_moves_tuple())\n",
    "            history, _ = tmp_board.history(self.history_flip)\n",
    "            for idx in range(self.num_planes):\n",
    "                batch[nodes_found, idx] = history[idx]\n",
    "            nodes_found += 1\n",
    "\n",
    "        if nodes_found == 0:\n",
    "            return root\n",
    "\n",
    "        values, policy_logits = make_predictions_py(\n",
    "            trt_func=trt_func,\n",
    "            batch=batch\n",
    "        )\n",
    "        \n",
    "        for idx in range(nodes_found):\n",
    "            self.expand_and_evaluate_node(nodes_to_eval[idx], policy_logits[idx], eval_nodes_legal_moves[idx], debug)\n",
    "            value = value_to_01_py(values[idx].item())\n",
    "            update_py(root, moves_to_nodes[idx], value)\n",
    "            if debug:\n",
    "                nodes_to_eval[idx].debug_info[\"init_value\"] = flip_value_py(value)\n",
    "        return root\n",
    "\n",
    "    def find_best_move(self, board, root, trt_func, num_sims, time_limit, debug):\n",
    "        assert (num_sims > 0) != (time_limit > 0.0), \"Only one & at least one, either num_sims or time_limit, must be greater than 0.\"\n",
    "\n",
    "        batch = np.zeros((self.num_vl_searches, self.num_planes), dtype=np.int64)\n",
    "        time_limit_set = True if time_limit > 0.0 else False\n",
    "\n",
    "        if root is None or root.is_leaf():\n",
    "            root = NodePy(0.0)\n",
    "            root.to_play = board.to_play()\n",
    "\n",
    "        if root.is_leaf():\n",
    "            history, _ = board.history(self.history_flip)\n",
    "            for idx in range(self.num_planes):\n",
    "                batch[0, idx] = history[idx]\n",
    "            _, policy_logits = make_predictions_py(\n",
    "                    trt_func=trt_func,\n",
    "                    batch=batch\n",
    "                )\n",
    "            self.expand_and_evaluate_node(root, policy_logits[0], board.legal_moves_tuple(), debug)\n",
    "            root.N += 1\n",
    "\n",
    "        if self.root_exploration_noise:\n",
    "            add_exploration_noise_py(root, self.rng, self.root_dirichlet_alpha, self.root_exploration_fraction)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            if time_limit_set:\n",
    "                if time.time() - start_time > time_limit:\n",
    "                    break\n",
    "                nodes_to_find = self.num_vl_searches\n",
    "            else:\n",
    "                if root.N >= num_sims:\n",
    "                    break\n",
    "                nodes_to_find = self.num_vl_searches if root.N + self.num_vl_searches <= num_sims else num_sims - root.N\n",
    "            nodes_found = 0\n",
    "            nodes_to_eval = []\n",
    "            eval_nodes_legal_moves = []\n",
    "            moves_to_nodes = []\n",
    "            failsafe = 0\n",
    "            while nodes_found < nodes_to_find and failsafe < 2:\n",
    "                depth_to_root = 0\n",
    "                node = root\n",
    "                tmp_board = board.clone()\n",
    "                while not node.is_leaf():\n",
    "                    fpu = self.fpu_leaf if depth_to_root > 0 else self.fpu_root\n",
    "                    move_num = select_child_py(node, pb_c_base=self.pb_c_base, pb_c_init=self.pb_c_init, pb_c_factor=self.pb_c_factor, fpu=fpu, debug=debug)\n",
    "                    node = node[move_num]\n",
    "                    tmp_board.push_num(move_num)\n",
    "                    depth_to_root += 1\n",
    "                \n",
    "                terminal, is_drawn = tmp_board.mid_search_terminal(depth_to_root)\n",
    "                if terminal:\n",
    "                    value = 0.5 if is_drawn else 0.0\n",
    "                    update_py(root, tmp_board.moves_history(depth_to_root), value)\n",
    "                    if debug:\n",
    "                        node.debug_info[\"init_value\"] = flip_value_py(value)\n",
    "                    failsafe += 1\n",
    "                    continue\n",
    "\n",
    "                # If tablebase search is enabled, check if the position is in the tablebase\n",
    "                if self.tablebase_search and tmp_board.pieces_on_board() <= 5:\n",
    "                    tb_board = TbBoard(tmp_board.fen())\n",
    "                    wdl = self.tablebase.get_wdl(tb_board)\n",
    "                    if wdl is not None and not (wdl == 1 or wdl == -1):\n",
    "                        if wdl == 0:\n",
    "                            value = 0.5\n",
    "                        else:\n",
    "                            to_play = tmp_board.to_play()\n",
    "                            winner = to_play if wdl > 0 else not to_play\n",
    "                            value = 1.0 if winner == to_play else 0.0\n",
    "                        update_py(root, tmp_board.moves_history(depth_to_root), value)\n",
    "                        if debug:\n",
    "                            node.debug_info[\"init_value\"] = flip_value_py(value)\n",
    "                        failsafe += 1\n",
    "                        continue\n",
    "\n",
    "                moves_to_node = tmp_board.moves_history(depth_to_root)\n",
    "                add_vloss_py(root, moves_to_node)\n",
    "\n",
    "                node.to_play = tmp_board.to_play()\n",
    "\n",
    "                nodes_to_eval.append(node)\n",
    "                moves_to_nodes.append(moves_to_node)\n",
    "                eval_nodes_legal_moves.append(tmp_board.legal_moves_tuple())\n",
    "                history, _ = tmp_board.history(self.history_flip)\n",
    "                for idx in range(self.num_planes):\n",
    "                    batch[nodes_found, idx] = history[idx]\n",
    "                nodes_found += 1\n",
    "\n",
    "            if nodes_found == 0:\n",
    "                failsafe += 1\n",
    "                continue\n",
    "\n",
    "            values, policy_logits = make_predictions_py(\n",
    "                    trt_func=trt_func,\n",
    "                    batch=batch\n",
    "                )\n",
    "            \n",
    "            for idx in range(nodes_found):\n",
    "                self.expand_and_evaluate_node(nodes_to_eval[idx], policy_logits[idx], eval_nodes_legal_moves[idx], debug)\n",
    "                value = value_to_01_py(values[idx].item())\n",
    "                update_py(root, moves_to_nodes[idx], value)\n",
    "                if debug:\n",
    "                    nodes_to_eval[idx].debug_info[\"init_value\"] = flip_value_py(value)\n",
    "\n",
    "        end_time = time.time()\n",
    "        if debug:\n",
    "            root.debug_info[\"elapsed_time\"] = end_time - start_time\n",
    "        \n",
    "        move_num = self.select_best_move(root, temp=self.moves_softmax_temp if board.ply() <= self.num_mcts_sampling_moves else 0.0)\n",
    "        child_visits = self.calculate_search_statistics(root)\n",
    "        \n",
    "        if board.ply() > self.num_mcts_sampling_moves and self.resignation_threshold > 0.0:\n",
    "            q = root[move_num].W / root[move_num].N if root[move_num].N > 0 else self.fpu_root\n",
    "            if q < self.resignation_threshold:\n",
    "                move_num = 0 # Resignation move\n",
    "\n",
    "        return move_num, root, child_visits\n",
    "\n",
    "    def expand_and_evaluate_node(self, node, policy_logits, legal_moves_tuple, debug):\n",
    "        m = self.m_w if node.to_play else self.m_b\n",
    "        moves_count = len(legal_moves_tuple)\n",
    "        policy = np.zeros(moves_count, dtype=np.float32)\n",
    "        \n",
    "        for i in range(moves_count):\n",
    "            move_uci = legal_moves_tuple[i][1]\n",
    "            p_idx = m[move_uci]\n",
    "            p = policy_logits[p_idx]\n",
    "            policy[i] = p\n",
    "\n",
    "        # Softmax\n",
    "        _max = np.max(policy)\n",
    "        policy = policy - _max\n",
    "        exp_policy = np.exp(policy)\n",
    "        policy = exp_policy / np.sum(exp_policy)\n",
    "\n",
    "        for i in range(moves_count):\n",
    "            node.add_child(legal_moves_tuple[i][0], policy[i])\n",
    "        if debug:\n",
    "            for i in range(moves_count):\n",
    "                child = node.children[legal_moves_tuple[i][0]]\n",
    "                child.debug_info[\"move_uci\"] = legal_moves_tuple[i][1]\n",
    "                child.debug_info[\"move_num\"] = legal_moves_tuple[i][0]\n",
    "\n",
    "    def calculate_search_statistics(self, root):\n",
    "        child_visits = np.zeros(1858, dtype=np.float32)\n",
    "        m = self.m_w if root.to_play else self.m_b\n",
    "        \n",
    "        _sum = 0.0\n",
    "        for move_num, child in root.children.items():\n",
    "            cN = child.N\n",
    "            move_str = Move(move_num).uci()\n",
    "            i = m[move_str]\n",
    "            child_visits[i] = float(cN)\n",
    "            _sum += float(cN)\n",
    "        child_visits /= _sum\n",
    "        return child_visits\n",
    "\n",
    "    def select_best_move(self, node, temp):\n",
    "        moves = list(node.children.keys())\n",
    "        probs = np.array([node[move].N for move in moves])\n",
    "        if temp == 0.0:\n",
    "            return moves[np.argmax(probs)]\n",
    "        else:\n",
    "            probs = np.power(probs, 1.0 / temp)\n",
    "            probs /= np.sum(probs)\n",
    "            return self.rng.choice(moves, p=probs)\n",
    "\n",
    "# Helper functions\n",
    "def add_exploration_noise_py(node, rng, dirichlet_alpha, exploration_fraction):\n",
    "    noise = rng.dirichlet([dirichlet_alpha] * len(node.children)).astype(np.float32)\n",
    "    \n",
    "    i = 0\n",
    "    for child in node.children.values():\n",
    "        child.P = child.P * (1 - exploration_fraction) + noise[i] * exploration_fraction\n",
    "        i += 1\n",
    "\n",
    "def make_predictions_py(trt_func, batch):\n",
    "    if is_trt_func(trt_func):\n",
    "        values_tf, policy_logits_tf = predict_fn(\n",
    "            trt_func=trt_func,\n",
    "            images=batch\n",
    "        )\n",
    "        values = np.array(values_tf, dtype=np.float32)\n",
    "        policy_logits = np.array(policy_logits_tf, dtype=np.float32)\n",
    "        return values, policy_logits\n",
    "    else:\n",
    "        values, policy_logits = predict_model(\n",
    "            model=trt_func,\n",
    "            images=batch\n",
    "        )\n",
    "        values = np.array(values, dtype=np.float32)\n",
    "        policy_logits = np.array(policy_logits, dtype=np.float32)\n",
    "        return values, policy_logits\n",
    "\n",
    "\n",
    "def select_child_py(node, pb_c_base, pb_c_init, pb_c_factor, fpu, debug):\n",
    "    bestmove = 0\n",
    "    bestucb = -99.9\n",
    "    N = node.N\n",
    "    pN_sqrt = math.sqrt(N)\n",
    "    pb_c = PB_C_py(N, pb_c_base, pb_c_init, pb_c_factor)\n",
    "\n",
    "    for move, child in node.children.items():\n",
    "        cN = child.N\n",
    "        cQ = child.W / cN if cN > 0 else fpu\n",
    "        ucb = cQ + UCB_py(cN, child.P, pN_sqrt, pb_c)\n",
    "        if ucb > bestucb:\n",
    "            bestucb = ucb\n",
    "            bestmove = move\n",
    "        if debug:\n",
    "            child.debug_info[\"ucb\"] = ucb\n",
    "    \n",
    "    return bestmove \n",
    "\n",
    "def UCB_py(cN, cP, pN_sqrt, pb_c):\n",
    "    return pb_c * cP * (pN_sqrt / (cN + 1))\n",
    "\n",
    "def PB_C_py(pN, pb_c_base, pb_c_init, pb_c_factor):\n",
    "    return math.log((pN + pb_c_base + 1) / pb_c_base) * pb_c_factor + pb_c_init\n",
    "\n",
    "def value_to_01_py(value):\n",
    "    return (value + 1.0) / 2.0\n",
    "\n",
    "def clip_value_py(value, amount):\n",
    "    max_value = 1.0 - amount\n",
    "    if value > max_value:\n",
    "        return max_value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def flip_value_py(value):\n",
    "    return 1.0 - value\n",
    "\n",
    "def update_py(root, moves_to_leaf, value):\n",
    "    root.N += 1\n",
    "    node = root\n",
    "    moves_count = len(moves_to_leaf)\n",
    "    if moves_count % 2 == 1:\n",
    "        value = flip_value_py(value)\n",
    "    for move in moves_to_leaf:\n",
    "        node = node[move]\n",
    "        node.remove_vloss()\n",
    "        node.N += 1\n",
    "        node.W += value\n",
    "        value = flip_value_py(value)\n",
    "\n",
    "def add_vloss_py(root, moves_to_leaf):\n",
    "    node = root\n",
    "    for move in moves_to_leaf:\n",
    "        node = node[move]\n",
    "        node.apply_vloss()\n",
    "\n",
    "def is_trt_func(obj):\n",
    "    # TensorRT function is a _WrapperFunction with a 'structured_input_signature' attribute\n",
    "    return hasattr(obj, 'structured_input_signature') and callable(obj)\n",
    "\n",
    "print(\"Python MCTS implementation loaded for performance comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self, board, root, trt_func, num_sims, time_limit, debug):\n",
    "def test_mcts_performance(model, mctsSearch, num_simulations=800, time_limit=10, runs=5):\n",
    "    board = Board()\n",
    "    times = []\n",
    "    nps_counts = []\n",
    "    if time_limit > 0.0:\n",
    "        num_simulations = 0\n",
    "    for i in range(runs):\n",
    "        t1 = time.time()\n",
    "        _, root, _ = mctsSearch.find_best_move(\n",
    "            board,\n",
    "            None,\n",
    "            model,\n",
    "            num_sims=num_simulations,\n",
    "            time_limit=time_limit,\n",
    "            debug=False)\n",
    "        t2 = time.time()\n",
    "        times.append(t2 - t1)\n",
    "        nps_counts.append(root.N / time_limit)\n",
    "        del root\n",
    "    avg_time = sum(times) / len(times)\n",
    "    avg_nps = sum(nps_counts) / len(nps_counts)\n",
    "    return avg_nps, avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1903174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import generate_model, update_trt_model, load_as_trt_model\n",
    "from configs import defaultConfig\n",
    "\n",
    "fp32_model_1 = \"test_fp32_1\"\n",
    "fp32_model_16 = \"test_fp32_16\"\n",
    "fp32_model_32 = \"test_fp32_32\"\n",
    "\n",
    "fp16_model_1 = \"test_fp16_1\"\n",
    "fp16_model_16 = \"test_fp16_16\"\n",
    "fp16_model_32 = \"test_fp16_32\"\n",
    "\n",
    "#model = generate_model()\n",
    "#data_dir = os.path.join(defaultConfig['project_dir'], 'data')\n",
    "#model.save(os.path.join(data_dir, 'models', 'model.keras'))\n",
    "\n",
    "\"\"\" defaultConfig['num_vl_searches'] = 1\n",
    "update_trt_model(defaultConfig, fp32_model_1, precision_mode='FP32')\n",
    "update_trt_model(defaultConfig, fp16_model_1, precision_mode='FP16')\n",
    "\n",
    "defaultConfig['num_vl_searches'] = 16\n",
    "update_trt_model(defaultConfig, fp32_model_16, precision_mode='FP32')\n",
    "update_trt_model(defaultConfig, fp16_model_16, precision_mode='FP16')\n",
    "\n",
    "defaultConfig['num_vl_searches'] = 32\n",
    "update_trt_model(defaultConfig, fp32_model_32, precision_mode='FP32')\n",
    "update_trt_model(defaultConfig, fp16_model_32, precision_mode='FP16') \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each test now appends its results as: (Implementation, Model_Precision, Virtual_Loss, Avg_NPS)\n",
    "performance_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd64cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(defaultConfig['project_dir'], 'data', 'models', 'model.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineplayConfig['num_vl_searches'] = 1\n",
    "mctsPy = MCTSPy(engineplayConfig)\n",
    "_, _ = test_mcts_performance(model, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(model, mctsPy, time_limit=10, runs=10)\n",
    "performance_results.append(('RustChess', 'Python', 'Model', 'None', 1, avg_nps))\n",
    "\n",
    "engineplayConfig['num_vl_searches'] = 16\n",
    "mctsPy = MCTSPy(engineplayConfig)\n",
    "_, _ = test_mcts_performance(model, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(model, mctsPy, time_limit=10, runs=10)\n",
    "performance_results.append(('RustChess', 'Python', 'Model', 'None', 16, avg_nps))\n",
    "\n",
    "engineplayConfig['num_vl_searches'] = 32\n",
    "mctsPy = MCTSPy(engineplayConfig)\n",
    "_, _ = test_mcts_performance(model, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(model, mctsPy, time_limit=10, runs=10)\n",
    "performance_results.append(('RustChess', 'Python', 'Model', 'None', 32, avg_nps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineplayConfig['num_vl_searches'] = 1\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(model, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(model, mctsCy, time_limit=10, runs=10)\n",
    "performance_results.append(('RustChess', 'Cython', 'Model', 'None', 1, avg_nps))\n",
    "\n",
    "engineplayConfig['num_vl_searches'] = 16\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(model, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(model, mctsCy, time_limit=10, runs=10)\n",
    "performance_results.append(('RustChess', 'Cython', 'Model', 'None', 16, avg_nps))\n",
    "\n",
    "engineplayConfig['num_vl_searches'] = 32\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(model, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(model, mctsCy, time_limit=10, runs=10)\n",
    "performance_results.append(('RustChess', 'Cython', 'Model', 'None', 32, avg_nps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710666a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d155e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_func, loaded_model = load_as_trt_model(fp32_model_1)\n",
    "engineplayConfig['num_vl_searches'] = 1\n",
    "\n",
    "# Python, FP32, no virtual loss\n",
    "mctsPy = MCTSPy(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsPy, time_limit=10, runs=5)\n",
    "print(f\"[PythonMCTS][FP32][VL_1] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Python\", \"FP32\", 1, avg_nps))\n",
    "\n",
    "# Cython, FP32, no virtual loss\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsCy, time_limit=10, runs=5)\n",
    "print(f\"[CythonMCTS][FP32][VL_1] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Cython\", \"FP32\", 1, avg_nps))\n",
    "\n",
    "del trt_func, loaded_model\n",
    "trt_func, loaded_model = load_as_trt_model(fp16_model_1)\n",
    "\n",
    "# Python, FP16, no virtual loss\n",
    "_, _ = test_mcts_performance(trt_func, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsPy, time_limit=10, runs=5)\n",
    "print(f\"[PythonMCTS][FP16][VL_1] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Python\", \"FP16\", 1, avg_nps))\n",
    "\n",
    "# Cython, FP16, no virtual loss\n",
    "_, _ = test_mcts_performance(trt_func, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsCy, time_limit=10, runs=5)\n",
    "print(f\"[CythonMCTS][FP16][VL_1] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Cython\", \"FP16\", 1, avg_nps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trt_func, loaded_model\n",
    "trt_func, loaded_model = load_as_trt_model(fp32_model_16)\n",
    "engineplayConfig['num_vl_searches'] = 16\n",
    "\n",
    "# Python, FP32, virtual loss 16\n",
    "mctsPy = MCTSPy(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsPy, time_limit=10, runs=5)\n",
    "print(f\"[PythonMCTS][FP32][VL_16] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Python\", \"FP32\", 16, avg_nps))\n",
    "\n",
    "# Cython, FP32, virtual loss 16\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsCy, time_limit=10, runs=5)\n",
    "print(f\"[CythonMCTS][FP32][VL_16] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Cython\", \"FP32\", 16, avg_nps))\n",
    "\n",
    "del trt_func, loaded_model\n",
    "trt_func, loaded_model = load_as_trt_model(fp16_model_16)\n",
    "\n",
    "# Python, FP16, virtual loss 16\n",
    "_, _ = test_mcts_performance(trt_func, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsPy, time_limit=10, runs=5)\n",
    "print(f\"[PythonMCTS][FP16][VL_16] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Python\", \"FP16\", 16, avg_nps))\n",
    "\n",
    "# Cython, FP16, virtual loss 16\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsCy, time_limit=10, runs=5)\n",
    "print(f\"[CythonMCTS][FP16][VL_16] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Cython\", \"FP16\", 16, avg_nps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del trt_func, loaded_model\n",
    "trt_func, loaded_model = load_as_trt_model(fp32_model_32)\n",
    "engineplayConfig['num_vl_searches'] = 32\n",
    "\n",
    "# Python, FP32, virtual loss 32\n",
    "mctsPy = MCTSPy(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsPy, time_limit=10, runs=5)\n",
    "print(f\"[PythonMCTS][FP32][VL_32] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Python\", \"FP32\", 32, avg_nps))\n",
    "\n",
    "# Cython, FP32, virtual loss 32\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsCy, time_limit=10, runs=5)\n",
    "print(f\"[CythonMCTS][FP32][VL_32] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Cython\", \"FP32\", 32, avg_nps))\n",
    "\n",
    "del trt_func, loaded_model\n",
    "trt_func, loaded_model = load_as_trt_model(fp16_model_32)\n",
    "\n",
    "# Python, FP16, virtual loss 32\n",
    "_, _ = test_mcts_performance(trt_func, mctsPy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsPy, time_limit=10, runs=5)\n",
    "print(f\"[PythonMCTS][FP16][VL_32] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Python\", \"FP16\", 32, avg_nps))\n",
    "\n",
    "# Cython, FP16, virtual loss 32\n",
    "mctsCy = MCTS(engineplayConfig)\n",
    "_, _ = test_mcts_performance(trt_func, mctsCy, num_simulations=50, runs=1) # warmup\n",
    "avg_nps, avg_time = test_mcts_performance(trt_func, mctsCy, time_limit=10, runs=5)\n",
    "print(f\"[CythonMCTS][FP16][VL_32] - Average NPS: {avg_nps:.1f}\")\n",
    "performance_results.append((\"RustChess\", \"Cython\", \"FP16\", 32, avg_nps))\n",
    "\n",
    "del trt_func, loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d506ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import Board as PyBoard\n",
    "from rchess import Board as RBoard\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def pyboard_perft(board, depth):\n",
    "    if depth == 0:\n",
    "        return 1\n",
    "    nodes = 0\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        nodes += pyboard_perft(board, depth - 1)\n",
    "        board.pop()\n",
    "    return nodes\n",
    "\n",
    "# For RBoard (rchess), assuming similar API\n",
    "def rboard_perft(board, depth):\n",
    "    if depth == 0:\n",
    "        return 1\n",
    "    nodes = 0\n",
    "    for move in board.legal_moves():\n",
    "        board_copy = board.clone()\n",
    "        board_copy.push(move)\n",
    "        nodes += rboard_perft(board_copy, depth - 1)\n",
    "    return nodes\n",
    "\n",
    "perft_results = []\n",
    "POSITIONS = {\n",
    "    \"Initial\": \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\",\n",
    "    \"KiwiPete (Pos 2)\": \"r3k2r/p1ppqpb1/bn2pnp1/3PN3/1p2P3/2N2Q1p/PPPBBPPP/R3K2R w KQkq - \",\n",
    "    \"Pos 3\": \"8/2p5/3p4/KP5r/1R3p1k/8/4P1P1/8 w - - 0 1 \"\n",
    "}\n",
    "DEPTHS = [3, 4] # Using [3, 4] as depth 5 can be very slow\n",
    "RUNS = 5\n",
    "\n",
    "def run_perft_test(board_class, perft_func, fen, depth, runs):\n",
    "    \"\"\"Runs perft test for a given board, depth, and number of runs, returning avg time and node count.\"\"\"\n",
    "    times = []\n",
    "    nodes = 0\n",
    "    for _ in range(runs):\n",
    "        board = board_class(fen)\n",
    "        start_time = time.time()\n",
    "        # Node count is constant, so we only need to calculate it once.\n",
    "        if nodes == 0:\n",
    "            nodes = perft_func(board, depth)\n",
    "        else:\n",
    "            perft_func(board, depth) # Still run it to measure time\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    return sum(times) / len(times), nodes\n",
    "\n",
    "for name, fen in POSITIONS.items():\n",
    "    for depth in DEPTHS:\n",
    "        print(f\"Testing Position: '{name}' at depth {depth}...\")\n",
    "\n",
    "        # Test python-chess\n",
    "        py_avg_time, py_nodes = run_perft_test(PyBoard, pyboard_perft, fen, depth, RUNS)\n",
    "        perft_results.append({\n",
    "            \"Position\": name,\n",
    "            \"Depth\": depth,\n",
    "            \"Library\": \"python-chess\",\n",
    "            \"Avg Time (s)\": py_avg_time,\n",
    "            \"Nodes\": py_nodes\n",
    "        })\n",
    "        print(f\"  python-chess: {py_nodes} nodes, avg time: {py_avg_time:.4f}s\")\n",
    "\n",
    "        # Test rchess\n",
    "        r_avg_time, r_nodes = run_perft_test(RBoard, rboard_perft, fen, depth, RUNS)\n",
    "        perft_results.append({\n",
    "            \"Position\": name,\n",
    "            \"Depth\": depth,\n",
    "            \"Library\": \"rchess\",\n",
    "            \"Avg Time (s)\": r_avg_time,\n",
    "            \"Nodes\": r_nodes\n",
    "        })\n",
    "        print(f\"  rchess: {r_nodes} nodes, avg time: {r_avg_time:.4f}s\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Display results in a pandas DataFrame\n",
    "df_perft = pd.DataFrame(perft_results)\n",
    "print(\"\\nPerft Test Summary:\")\n",
    "print(df_perft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be451a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import Board as PyBoard\n",
    "from rchess import Board as RBoard\n",
    "import time\n",
    "\n",
    "\n",
    "POSITION2 = \"r3k2r/p1ppqpb1/bn2pnp1/3PN3/1p2P3/2N2Q1p/PPPBBPPP/R3K2R w KQkq - \"\n",
    "POSITION3 = \"8/2p5/3p4/KP5r/1R3p1k/8/4P1P1/8 w - - 0 1 \"\n",
    "\n",
    "def pyboard_perft(board, depth):\n",
    "    if depth == 0:\n",
    "        return 1\n",
    "    nodes = 0\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        nodes += pyboard_perft(board, depth - 1)\n",
    "        board.pop()\n",
    "    return nodes\n",
    "\n",
    "# For RBoard (rchess), assuming similar API\n",
    "def rboard_perft(board, depth):\n",
    "    if depth == 0:\n",
    "        return 1\n",
    "    nodes = 0\n",
    "    for move in board.legal_moves():\n",
    "        board_copy = board.clone()\n",
    "        board_copy.push(move)\n",
    "        nodes += rboard_perft(board_copy, depth - 1)\n",
    "    return nodes\n",
    "\n",
    "# INITIAL POSITION\n",
    "pyboard = PyBoard()\n",
    "rboard = RBoard()\n",
    "\n",
    "DEPTH = 3\n",
    "\n",
    "t1 = time.time()\n",
    "py_nodes = pyboard_perft(pyboard, DEPTH)\n",
    "t2 = time.time()\n",
    "py_elapsed = t2 - t1\n",
    "\n",
    "t3 = time.time()\n",
    "r_nodes = rboard_perft(rboard, DEPTH)\n",
    "t4 = time.time()\n",
    "r_elapsed = t4 - t3\n",
    "\n",
    "print(f\"python-chess POS1 perft({DEPTH}): {py_nodes} nodes in {py_elapsed:.4f} seconds\")\n",
    "print(f\"rchess POS1 perft({DEPTH}): {r_nodes} nodes in {r_elapsed:.4f} seconds\")\n",
    "\n",
    "# POSITION 2 A.K.A KiwiPete\n",
    "pyboard = PyBoard(POSITION2)\n",
    "rboard = RBoard(POSITION2)\n",
    "t1 = time.time()\n",
    "py_nodes = pyboard_perft(pyboard, DEPTH)\n",
    "t2 = time.time()\n",
    "py_elapsed = t2 - t1\n",
    "\n",
    "t3 = time.time()\n",
    "r_nodes = rboard_perft(rboard, DEPTH)\n",
    "t4 = time.time()\n",
    "r_elapsed = t4 - t3\n",
    "\n",
    "print(f\"python-chess POS1 perft({DEPTH}): {py_nodes} nodes in {py_elapsed:.4f} seconds\")\n",
    "print(f\"rchess POS1 perft({DEPTH}): {r_nodes} nodes in {r_elapsed:.4f} seconds\")\n",
    "\n",
    "# POSITION 3 \n",
    "pyboard = PyBoard(POSITION3)\n",
    "rboard = RBoard(POSITION3)\n",
    "t1 = time.time()\n",
    "py_nodes = pyboard_perft(pyboard, DEPTH)\n",
    "t2 = time.time()\n",
    "py_elapsed = t2 - t1\n",
    "\n",
    "t3 = time.time()\n",
    "r_nodes = rboard_perft(rboard, DEPTH)\n",
    "t4 = time.time()\n",
    "r_elapsed = t4 - t3\n",
    "\n",
    "print(f\"python-chess POS1 perft({DEPTH}): {py_nodes} nodes in {py_elapsed:.4f} seconds\")\n",
    "print(f\"rchess POS1 perft({DEPTH}): {r_nodes} nodes in {r_elapsed:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a349af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_results[8])\n",
    "#performance_results[8] = (\"Python\", \"FP32\", 32, performance_results[8][3])  # Update the implementation name for consistency\n",
    "new_performance_results = []\n",
    "for lang, precision, vl, nps in performance_results:\n",
    "    new_performance_results.append((\"RustChess\", lang, precision, vl, nps))\n",
    "print(new_performance_results)\n",
    "performance_results = new_performance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Comparison Results\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame from results\n",
    "df = pd.DataFrame(performance_results, columns=['Library', 'Implementation', 'Model_Precision', 'Virtual_Loss', 'Avg_NPS'])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MCTS PERFORMANCE COMPARISON RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Main comparison table\n",
    "print(\"Complete Results:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (lib, impl, precision, vl, nps) in enumerate(performance_results):\n",
    "    print(f\"{i+1:2d}. {lib:7s} | {impl:7s} | {precision:4s} | VL={vl:2d} | NPS: {nps:8.1f}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Group by implementation for direct comparison\n",
    "python_results = [r for r in performance_results if r[0] == 'Python']\n",
    "cython_results = [r for r in performance_results if r[0] == 'Cython']\n",
    "\n",
    "print(\"SIDE-BY-SIDE COMPARISON:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Configuration':<25} {'Python NPS':<15} {'Cython NPS':<15} {'Speedup':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Pair up results by configuration\n",
    "configurations = {}\n",
    "for lib, impl, precision, vl, nps in performance_results:\n",
    "    config_key = f\"{precision}, VL={vl}\"\n",
    "    if config_key not in configurations:\n",
    "        configurations[config_key] = {}\n",
    "    configurations[config_key][impl] = nps\n",
    "\n",
    "for config, results in configurations.items():\n",
    "    if 'Python' in results and 'Cython' in results:\n",
    "        python_nps = results['Python']\n",
    "        cython_nps = results['Cython']\n",
    "        speedup = cython_nps / python_nps\n",
    "        print(f\"{config:<25} {python_nps:<15.1f} {cython_nps:<15.1f} {speedup:<10.2f}x\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Summary statistics\n",
    "if python_results and cython_results:\n",
    "    avg_python = sum(r[3] for r in python_results) / len(python_results)\n",
    "    avg_cython = sum(r[3] for r in cython_results) / len(cython_results)\n",
    "    overall_speedup = avg_cython / avg_python\n",
    "    \n",
    "    print(\"SUMMARY:\")\n",
    "    print(f\"Average Python NPS:  {avg_python:8.1f}\")\n",
    "    print(f\"Average Cython NPS:  {avg_cython:8.1f}\")\n",
    "    print(f\"Overall Speedup:     {overall_speedup:8.2f}x\")\n",
    "    print()\n",
    "    \n",
    "    # Find best and worst performing configurations\n",
    "    best_config = max(performance_results, key=lambda x: x[3])\n",
    "    worst_config = min(performance_results, key=lambda x: x[3])\n",
    "    \n",
    "    print(f\"Best Performance:  {best_config[0]} {best_config[1]} VL={best_config[2]} - {best_config[3]:.1f} NPS\")\n",
    "    print(f\"Worst Performance: {worst_config[0]} {worst_config[1]} VL={worst_config[2]} - {worst_config[3]:.1f} NPS\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93423096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3b872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8199bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
